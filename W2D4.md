# Big-O
- how quickly the runtime grows relative to the input, as the input gets arbitrarily large
## Motivation
- Want to know the scalability between algorithm A vs algorithm B
    - Major factors includes number of steps and input
## Model of Computation: RAM
- What constitutes as a step?
- RAM = Random Access Machines
    - mathematical operators and comparison operators step: 1 step
    - loop step: n(how many times we are looping) * #(number of steps in each iteration)
    - Memory access(variables) and function calls: 1 step
    - No constant step
### Asymptotic Analysis
- behavior of a line as it approaches its limit (infinity)
    - constant don't effect the behavior of the line, only shift the line
- When you're calculating the big O complexity of something, you just throw out the constants
- [Calculate graph](desmos.com/calculator)
- x: input size, y: steps
- Ignore constant
    - y = 3n + 1 runtime: n  
    - y = 2710 runtime: 1 (when there is only a integer)
- When we asymptoticly analyze an algorithm, you only consider the dominate term (bottle neck- slowest part of your algorithm, only as fast as your bottleneck).
    - dominate term
        - e.g. 3n + 1 => 3n is the dominate term as n gets bigger the 1 becomes insignificant
- the worst case
    - Big O is the asymptotic worst case runtime => O(n)
    - when the value we are looking for isn't in the input
### common classifications
- N could be the actual input, or the size of the input
Both of these functions have O(n) runtime, even though one takes an integer as its input and the other takes an array:
``` ruby
def say_hi_n_times(n)
  n.times { puts "hi" }
end

def print_all_items_in_array(the_array)
  the_array.each do |item|
      puts item
  end
end
```
- fastest to slowest
    - O(1) - constant time algorithm
    - O(log n) - logarithmic (inverse of an exponent - input space is being divided)
    - O(n) - linear time (a loop)
    - O(nlog n) - log linear (merge sort, quick sort: best and avg)
    - O(n^2) - quadratic time (bubble sort, nested loops x2)
        - O(n^k) - polynomial (k must be >= 2)
    - O(2^n) - (subset, exponential)
    - O(n!) - (factorial, permutation)
- It shows how an algorithm scales.

    -O(n2): known as Quadratic complexity

    1 item: 1 second
    10 items: 100 seconds
    100 items: 10000 seconds
    Notice that the number of items increases by a factor of 10, but the time increases by a factor of 102. Basically, n=10 and so O(n2) gives us the scaling factor n2 which is 102.

    -O(n): known as Linear complexity

    1 item: 1 second
    10 items: 10 seconds
    100 items: 100 seconds
    This time the number of items increases by a factor of 10, and so does the time. n=10 and so O(n)'s scaling factor is 10.

    O(1): known as Constant complexity

    1 item: 1 second
    10 items: 1 second
    100 items: 1 second
    The number of items is still increasing by a factor of 10, but the scaling factor of O(1) is always 1.

    -O(log n): known as Logarithmic complexity

    1 item: 1 second
    10 items: 2 seconds
    100 items: 3 seconds
    1000 items: 4 seconds
    10000 items: 5 seconds
    The number of computations is only increased by a log of the input value. So in this case, assuming each computation takes 1 second, the log of the input n is the time required, hence log n.
## set definition ????????
- O(g) = {function} => function doesn't dominate g
    - if g = O(n^2) == O(n!)
## space complexity
- how much resource the algorithm is taking up relative to the size of the input, how this take up of resources scales as the input size grows
- how much memory is being taking up
- "exclusive or" aka "X OR" `^`
___________Readings___________
# [Plain English explanation of Big O -fullstack](https://stackoverflow.com/questions/487258/what-is-a-plain-english-explanation-of-big-o-notation)
# [Big O notation](https://www.interviewcake.com/article/ruby/big-o-notation-time-and-space-complexity)
# [Merge sort](http://www.algomation.com/player?algorithm=551321f6e1b6fa0300aae4d0) and [Bubble sort](http://www.algomation.com/player?algorithm=541a6ea7a7fe980200089c5e) visualization
# Bio O cheatsheet
- [space and time Big-O complexities of common algorithms](http://bigocheatsheet.com/)
- list of the best, average, and worst case complexities for search and sorting algorithms
# []()
___________
# CSS advanced selectors
- [List of selectors](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors)
## Attribute selectors
- specify attribute for target elements `[]`
``` CSS
input[type="radio"] {
    -webkit-appearance: none;
    width: 27px;
    height: 27px;
    cursor: pointer;
    background-image: url(../assets/stars.png);
    vertical-align: bottom;
    outline: none;
}
```
## pseudo selectors
- [pseudo](https://developer.mozilla.org/en-US/docs/Web/CSS/Pseudo-classes)
-  a keyword added to a selector that specifies a special state of the selected element
### State selectors
``` CSS
input[type="submit"]:hover {
    -webkit-filter: brightness(90%);
    /* advanced webkit property
    The -webkit-appearance property is native to the Webkit rendering engine used by Safari and Chrome. The -webkit- part of the property is called a vendor prefix. It's used to declare that this CSS property is from a proprietary rendering engine not yet declared by CSS W3 standards */
}
```
### structural selectors
- pseudo selectors target based on the structure of the HTML document
``` css
table tr:nth-of-type(2n) {
    background-color: whitesmoke;
    /*select every other table row element that is a descendent of a table element. It applies a greyish background color.*/
}
```
### combinators
- use SelectorA + SelectorB to target all SelectorB elements that immediately follow SelectorA elements
``` CSS
div ~ p {
    background-color: gold;
    /*This example uses the ~ combinator to make a general selection of subsequent siblings. It would select all <p> elements that follow and are within the same parent as any <div> elements.*/
}
```
